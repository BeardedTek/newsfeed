[{"id":0,"href":"/docs/docs/","title":"Documentation","section":"NewsFeed Documentation","content":" NewsFeed Documentation # Welcome to the comprehensive documentation for NewsFeed. Use the navigation menu to explore different sections.\nDocumentation Sections # User Guides # Frontend Usage Guide - Learn how to use the NewsFeed interface Admin Dashboard Guide - Manage and configure your NewsFeed instance Technical Documentation # Backend API Documentation - Explore the API endpoints Worker Tasks - Learn about background processing Authentication - Understanding the authentication system Deployment # Deployment Guides - Deploy NewsFeed on various platforms Docker Optimizations - Production-ready container configurations Frontend Environment Variables - Configure frontend without rebuilding Backend Environment Variables - Configure backend and worker services Git Hooks - Automated workflows for development Platform-Specific Guides - Instructions for specific platforms "},{"id":1,"href":"/docs/docs/frontend/","title":"Frontend Usage Guide","section":"Documentation","content":" Frontend Usage Guide # This section provides detailed information on how to use the NewsFeed frontend interface.\nNavigation # The NewsFeed interface consists of several key areas:\nMain Navigation Bar - Access different sections of the application News Feed - Browse through aggregated news articles Article View - Read individual articles Source Filters - Filter content by sources Category Filters - Filter content by categories Features # News Feed # The News Feed displays a collection of articles from various sources. Each article card shows:\nArticle title Source name Publication date Brief description Thumbnail image (if available) Click on any article card to read the full content.\nArticle Search # Use the search bar at the top of the page to find specific articles:\nClick on the search icon or press Ctrl+K (or Cmd+K on Mac) Enter your search query Press Enter or click the search button Browse through the search results Filtering Content # Filter content by:\nCategories - Click on a category tag to view articles in that category Sources - Select specific news sources from the sources menu Date Range - Filter articles by publication date User Preferences # Customize your news feed by setting preferences:\nLog in to your account Navigate to the user settings Set your preferred categories and sources Save your preferences Your news feed will be personalized based on these preferences.\nMobile Usage # The NewsFeed interface is fully responsive and works on mobile devices:\nSwipe left/right to navigate between sections Tap article cards to open them Use the hamburger menu to access navigation options "},{"id":2,"href":"/docs/docs/admin/","title":"Admin Dashboard Guide","section":"Documentation","content":" Admin Dashboard Guide # This section provides detailed information on how to use the NewsFeed admin dashboard to manage and configure your NewsFeed instance.\nNOTE: FEATURES MAY NOT BE COMPLETE # The features listed in this documentation may not be accurate. THe admin console is currently being planned out and this document serves as a guide to what it should look like when it is complete.\nAccessing the Admin Dashboard # To access the admin dashboard:\nLog in with an administrator account Click on the \u0026ldquo;Admin\u0026rdquo; link in the navigation bar You will be redirected to the admin dashboard Dashboard Overview # The admin dashboard provides several sections:\nOverview - System status and statistics Categories - Manage content categories Sources - Manage news sources Related Articles - Configure related article settings Settings - System-wide configuration Rebuild - Trigger system rebuilds and updates Managing Categories # The Categories section allows you to:\nView all existing categories Create new categories Edit category names and descriptions Delete categories Merge categories Adding a New Category # Navigate to the Categories section Click \u0026ldquo;Add New Category\u0026rdquo; Enter a name and description Click \u0026ldquo;Save\u0026rdquo; Editing Categories # Find the category in the list Click the \u0026ldquo;Edit\u0026rdquo; button Make your changes Click \u0026ldquo;Save\u0026rdquo; Managing Sources # The Sources section allows you to:\nView all configured news sources Add new sources Edit source details Enable/disable sources Delete sources Adding a New Source # Navigate to the Sources section Click \u0026ldquo;Add New Source\u0026rdquo; Enter the source details: Name URL Feed URL Category (optional) Click \u0026ldquo;Save\u0026rdquo; Related Articles # Configure how related articles are determined:\nSimilarity threshold Maximum number of related articles Algorithms used for determining relatedness System Settings # The Settings section allows you to configure:\nCache duration Default article display count Worker task frequency Authentication settings API rate limits Rebuilding the System # The Rebuild section provides tools to:\nRebuild the article index Clear caches Reprocess articles Update category assignments This is useful after making significant changes to categories or sources.\n"},{"id":3,"href":"/docs/docs/backend/","title":"Backend API Documentation","section":"Documentation","content":" Backend API Documentation # This section provides detailed information about the NewsFeed backend API endpoints.\nAPI Overview # The NewsFeed API is built using FastAPI and follows RESTful principles. All API endpoints are prefixed with /api.\nAuthentication # Most API endpoints require authentication. The API uses Casdoor for authentication and authorization.\nTo authenticate:\nObtain an access token from the Casdoor authentication endpoint\nInclude the token in the Authorization header of your requests:\nAuthorization: Bearer \u0026lt;your_token\u0026gt; API Endpoints # Articles # Endpoint Method Description /api/articles GET List articles with pagination /api/articles/{id} GET Get article by ID /api/articles/search GET Search articles /api/articles/latest GET Get latest articles /api/articles/popular GET Get popular articles List Articles # GET /api/articles Query parameters:\npage: Page number (default: 1) limit: Items per page (default: 20) category: Filter by category source: Filter by source from_date: Filter by date (format: YYYY-MM-DD) to_date: Filter by date (format: YYYY-MM-DD) Categories # Endpoint Method Description /api/categories GET List all categories /api/categories POST Create a new category (admin only) /api/categories/{id} GET Get category by ID /api/categories/{id} PUT Update a category (admin only) /api/categories/{id} DELETE Delete a category (admin only) /api/categories/{id}/articles GET Get articles in a category Sources # Endpoint Method Description /api/sources GET List all sources /api/sources POST Add a new source (admin only) /api/sources/{id} GET Get source by ID /api/sources/{id} PUT Update a source (admin only) /api/sources/{id} DELETE Delete a source (admin only) /api/sources/{id}/articles GET Get articles from a source Related Articles # Endpoint Method Description /api/related/{article_id} GET Get related articles /api/related POST Create related article connection (admin only) /api/related/{id} DELETE Delete related article connection (admin only) Thumbnails # Endpoint Method Description /api/thumbnails/{article_id} GET Get article thumbnail Admin # Endpoint Method Description /api/admin/rebuild POST Trigger system rebuild (admin only) /api/admin/settings GET Get system settings (admin only) /api/admin/settings PUT Update system settings (admin only) Response Format # All API responses follow a standard format:\n{ \u0026#34;status\u0026#34;: \u0026#34;success\u0026#34;, \u0026#34;data\u0026#34;: { // Response data here }, \u0026#34;message\u0026#34;: \u0026#34;Optional message\u0026#34; } For error responses:\n{ \u0026#34;status\u0026#34;: \u0026#34;error\u0026#34;, \u0026#34;error\u0026#34;: { \u0026#34;code\u0026#34;: \u0026#34;ERROR_CODE\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Error message\u0026#34; } } Rate Limiting # The API implements rate limiting to prevent abuse. Limits are:\n100 requests per minute for authenticated users 20 requests per minute for unauthenticated users When rate limited, the API will return a 429 status code.\n"},{"id":4,"href":"/docs/docs/deployment/docker-optimizations/","title":"Docker Optimizations","section":"Deployment Guides","content":" Docker Optimizations # NewsFeed uses optimized Docker containers for both development and production environments. This page documents the optimizations and best practices implemented in our Docker setup.\nMulti-Stage Builds # Both frontend and backend services use multi-stage builds to optimize container size and security:\nFrontend Multi-Stage Build # The frontend Dockerfile uses a four-stage build process:\nBase Stage: Sets up the common environment Dependencies Stage: Installs npm dependencies Build Stage: Compiles the Next.js application Runner Stage: Creates a minimal production image This approach significantly reduces the final image size by excluding development dependencies and build tools.\n# ---- Base Stage ---- FROM node:20-alpine AS base WORKDIR /app # ---- Dependencies Stage ---- FROM base AS dependencies COPY package*.json ./ RUN npm ci --omit=dev --no-audit --no-fund # ---- Build Stage ---- FROM dependencies AS builder COPY src ./src # ... copy other necessary files RUN npm run build # ---- Production Stage ---- FROM node:20-alpine AS runner # ... copy only the necessary files from builder Backend Multi-Stage Build # The backend Dockerfile uses a two-stage build process:\nBuilder Stage: Installs all dependencies and build tools Runtime Stage: Creates a minimal production image with only runtime dependencies # ---- Build Stage ---- FROM python:3.11-slim AS builder # ... install build dependencies and Python packages # ---- Runtime Stage ---- FROM python:3.11-slim AS runtime # ... copy only the necessary files from builder Security Enhancements # Non-Root User Execution # All services run as non-root users to enhance security:\nFrontend: Runs as the nextjs user Backend: Runs as the appuser user This reduces the risk of container breakouts and follows security best practices.\n# Frontend example RUN addgroup --system --gid 1001 nodejs \u0026amp;\u0026amp; \\ adduser --system --uid 1001 nextjs USER nextjs # Backend example RUN groupadd -r appuser \u0026amp;\u0026amp; useradd -r -g appuser appuser USER appuser Proper File Permissions # All files and directories have appropriate ownership and permissions:\n# Set proper ownership for files COPY --from=builder --chown=nextjs:nodejs /app/.next/standalone ./ RUN chown -R nextjs:nodejs /app Health Checks # All services include health checks for improved reliability:\nFrontend Health Check # HEALTHCHECK --interval=30s --timeout=5s --start-period=5s --retries=3 \\ CMD wget --no-verbose --tries=1 --spider http://localhost:3000/api/health || exit 1 Backend Health Check # HEALTHCHECK --interval=30s --timeout=5s --start-period=5s --retries=3 \\ CMD python -c \u0026#34;import requests; requests.get(\u0026#39;http://localhost:8001/api/health\u0026#39;)\u0026#34; || exit 1 Worker Health Check # HEALTHCHECK --interval=30s --timeout=10s --start-period=10s --retries=3 \\ CMD celery -A app.workers.tasks inspect ping || exit 1 Performance Optimizations # Minimal Base Images # All services use Alpine or slim base images to reduce size:\nFrontend: node:20-alpine Backend: python:3.11-slim Optimized Dependency Installation # Dependencies are installed with flags to reduce size and improve performance:\n# Frontend RUN npm ci --omit=dev --no-audit --no-fund # Backend RUN pip install --no-cache-dir -r requirements.txt Selective File Copying # Only necessary files are copied to each stage to improve build caching:\n# Copy only specific files instead of everything COPY src ./src COPY public ./public COPY next.config.js ./ Frontend Environment Variables # The frontend uses a runtime environment configuration system that allows changing environment variables without rebuilding the image:\nA template file (env-config.js) is included in the image At container startup, a script replaces placeholders with actual environment values The application loads this file at runtime to access the environment configuration This approach provides flexibility for deploying the same image to different environments.\nDocker Compose Integration # The docker-compose.yml file integrates all these optimizations:\nSpecifies the correct build target for multi-stage builds Configures health checks for all services Sets up proper dependency chains between services Configures logging with rotation Best Practices Summary # Use multi-stage builds to minimize image size Run containers as non-root users Implement health checks for all services Use minimal base images (Alpine/slim) Optimize dependency installation Copy only necessary files at each stage Use runtime environment configuration where possible Set proper file permissions and ownership "},{"id":5,"href":"/docs/docs/worker/","title":"Worker Tasks","section":"Documentation","content":" Worker Tasks # This section provides detailed information about the background worker tasks in NewsFeed.\nOverview # NewsFeed uses Celery for background task processing. These tasks handle resource-intensive operations such as:\nFetching articles from FreshRSS Processing article content Generating thumbnails Categorizing articles Finding related articles Purging old articles Task Architecture # The worker system consists of:\nCelery Workers - Process tasks from the queue Redis - Message broker and result backend Beat Scheduler - Schedules periodic tasks Environment Variables # The worker system can be configured using the following environment variables:\nTask Scheduling # WORKER_PROCESS_ARTICLES_INTERVAL: How often to process articles (in minutes, default: 15) WORKER_PURGE_OLD_ARTICLES_INTERVAL: How often to purge old articles (in minutes, default: 1440 - 24 hours) WORKER_ENRICH_ARTICLES_INTERVAL: How often to enrich articles (in minutes, default: 60 - 1 hour) Article Fetching and Retention # WORKER_FRESHRSS_FETCH_LIMIT: Maximum number of articles to fetch per batch (default: 100) WORKER_CONCURRENT_FRESHRSS_FETCH_TASKS: Number of concurrent fetch tasks (default: 1) WORKER_FRESHRSS_FETCH_DAYS: Number of days to look back for articles (default: 3) WORKER_FRESHRSS_PURGE_NUM_DAYS_TO_KEEP: Number of days to keep articles before purging (default: 7) Worker Performance # WORKER_TASK_TIME_LIMIT: Maximum time a task can run in seconds (default: 300 - 5 minutes) WORKER_SOFT_TIME_LIMIT: Soft time limit for tasks in seconds (default: 240 - 4 minutes) WORKER_MAX_TASKS_PER_CHILD: Maximum number of tasks a worker process can execute before being replaced (default: 100) WORKER_MAX_MEMORY_PER_CHILD: Maximum memory usage in KB before worker is replaced (default: 200000 - 200MB) WORKER_PREFETCH_MULTIPLIER: Number of tasks to prefetch per worker (default: 1) Main Tasks # Fetch Articles from FreshRSS # Task name: fetch_freshrss_articles\nThis task:\nConnects to the FreshRSS API Retrieves new articles since the last fetch Stores articles in the database Triggers processing tasks for each new article Schedule: Runs based on WORKER_PROCESS_ARTICLES_INTERVAL (default: every 15 minutes)\nProcess Article Content # Task name: process_article_content\nThis task:\nExtracts the main content from the article HTML Generates a summary using AI Creates a thumbnail from the article\u0026rsquo;s main image Analyzes the content for categorization Triggered by: fetch_freshrss_articles task\nGenerate Thumbnails # Task name: generate_thumbnail\nThis task:\nExtracts images from the article Selects the best image for a thumbnail Resizes and optimizes the image Saves the thumbnail to the filesystem Triggered by: process_article_content task\nCategorize Articles # Task name: categorize_article\nThis task:\nAnalyzes article content using AI Assigns categories based on content analysis Updates the article\u0026rsquo;s category associations Configuration:\nOLLAMA_URL: URL of the Ollama server OLLAMA_MODEL: AI model to use for categorization Triggered by: process_article_content task\nFind Related Articles # Task name: find_related_articles\nThis task:\nAnalyzes the article content Compares it with other articles in the database Establishes relationships between similar articles Schedule: Runs as part of the article processing workflow\nPurge Old Articles # Task name: purge_old_articles\nThis task:\nIdentifies articles older than the configured retention period Removes them from the database Deletes associated thumbnails Schedule: Runs based on WORKER_PURGE_OLD_ARTICLES_INTERVAL (default: every 24 hours)\nEnrich Articles # Task name: enrich_articles\nThis task:\nFinds articles with missing information (descriptions, images) Fetches and extracts content from the original article URLs Updates the articles with the enriched content Schedule: Runs based on WORKER_ENRICH_ARTICLES_INTERVAL (default: every hour)\nMonitoring Worker Tasks # You can monitor worker tasks through:\nCelery logs Redis monitoring tools Database queries for task status Troubleshooting # Common issues and solutions:\nTask Queue Buildup # Symptoms: Tasks are queuing up but not being processed\nSolutions:\nIncrease the number of worker processes Check for errors in worker logs Verify Redis connection Adjust WORKER_PREFETCH_MULTIPLIER if needed Memory Usage Issues # Symptoms: Workers consuming excessive memory\nSolutions:\nReduce WORKER_MAX_MEMORY_PER_CHILD value Implement task timeouts with WORKER_TASK_TIME_LIMIT Split large tasks into smaller chunks Failed Tasks # Symptoms: Tasks consistently failing\nSolutions:\nCheck worker logs for errors Verify external service connections (FreshRSS, Ollama) Test tasks manually using the Celery command line "},{"id":6,"href":"/docs/docs/deployment/runtime-environment/","title":"Frontend Environment Variables","section":"Deployment Guides","content":" Frontend Environment Variables # NewsFeed\u0026rsquo;s frontend application is designed to use environment variables at runtime rather than build time. This approach provides greater flexibility when deploying the same container image to different environments.\nHow It Works # The runtime environment configuration system consists of several components:\nEnvironment Variable Template: A JavaScript file with placeholders Replacement Script: A Node.js script that replaces placeholders with actual values Startup Script: A shell script that runs the replacement script before starting the application Browser Integration: Code that loads the environment configuration in the browser This approach allows you to change environment variables without rebuilding the Docker image.\nImplementation Details # Environment Variable Template # The template file (/public/env-config.js) contains placeholders for environment variables:\n// This file will be replaced at runtime with environment variables window.ENV_CONFIG = { NEXT_PUBLIC_CASDOOR_SERVER_URL: \u0026#34;__NEXT_PUBLIC_CASDOOR_SERVER_URL__\u0026#34;, NEXT_PUBLIC_CASDOOR_CLIENT_ID: \u0026#34;__NEXT_PUBLIC_CASDOOR_CLIENT_ID__\u0026#34;, // ... other variables }; Replacement Script # The Node.js script (/scripts/generate-env-config.js) replaces placeholders with actual environment variable values:\n#!/usr/bin/env node // Script to replace environment variable placeholders in env-config.js const fs = require(\u0026#39;fs\u0026#39;); const path = require(\u0026#39;path\u0026#39;); // Path to the env-config.js file const envConfigPath = path.join(process.cwd(), \u0026#39;public\u0026#39;, \u0026#39;env-config.js\u0026#39;); // Read the template file let content = fs.readFileSync(envConfigPath, \u0026#39;utf8\u0026#39;); // Define variable mappings (with and without NEXT_PUBLIC_ prefix) const envVarMappings = [ [\u0026#39;NEXT_PUBLIC_CASDOOR_SERVER_URL\u0026#39;, \u0026#39;CASDOOR_SERVER_URL\u0026#39;], // ... other mappings ]; // Replace each placeholder with its actual environment variable value envVarMappings.forEach(([nextPublicVar, plainVar]) =\u0026gt; { const placeholder = `__${nextPublicVar}__`; // First try with NEXT_PUBLIC_ prefix, then without const value = process.env[nextPublicVar] || process.env[plainVar] || \u0026#39;\u0026#39;; content = content.replace(placeholder, value); }); // Write the updated content back to the file fs.writeFileSync(envConfigPath, content, \u0026#39;utf8\u0026#39;); Startup Script # The shell script (/scripts/start.sh) runs the replacement script before starting the application:\n#!/bin/sh # Map non-prefixed environment variables to ones with NEXT_PUBLIC_ prefix if [ -n \u0026#34;$CASDOOR_SERVER_URL\u0026#34; ]; then export NEXT_PUBLIC_CASDOOR_SERVER_URL=$CASDOOR_SERVER_URL fi # ... other mappings # Generate the runtime environment configuration node /app/scripts/generate-env-config.js # Start the Next.js server exec node server.js Browser Integration # The application loads the environment configuration in the browser:\n// In layout.tsx import Script from \u0026#39;next/script\u0026#39;; export default function RootLayout({ children }) { return ( \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; {/* Load runtime environment configuration before any other scripts */} \u0026lt;Script src=\u0026#34;/env-config.js\u0026#34; strategy=\u0026#34;beforeInteractive\u0026#34; /\u0026gt; {/* ... other head content */} \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt;{children}\u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; ); } Accessing Environment Variables # The application code accesses environment variables through a helper function:\n// Helper function to get environment variables at runtime const getEnvVar = (key: string): string =\u0026gt; { if (typeof window !== \u0026#39;undefined\u0026#39; \u0026amp;\u0026amp; window.ENV_CONFIG \u0026amp;\u0026amp; window.ENV_CONFIG[key]) { return window.ENV_CONFIG[key]; } // Fallback to process.env during development or SSR return process.env[key] || \u0026#39;\u0026#39;; }; // Usage example const serverUrl = getEnvVar(\u0026#39;NEXT_PUBLIC_CASDOOR_SERVER_URL\u0026#39;); Simplified Environment Variable Names # For convenience, you can use environment variable names without the NEXT_PUBLIC_ prefix in your configuration files. The startup script automatically maps them to the prefixed versions required by Next.js.\nFor example, in your env/frontend file or Docker Compose configuration:\n# Instead of: NEXT_PUBLIC_CASDOOR_SERVER_URL=http://localhost:8000 # You can use: CASDOOR_SERVER_URL=http://localhost:8000 Benefits # This approach provides several benefits:\nDeployment Flexibility: Deploy the same image to different environments Simplified Configuration: Use cleaner environment variable names No Rebuilds: Change configuration without rebuilding the image Consistent Development: Use the same environment variable system in all environments Supported Environment Variables # The following environment variables are supported by the runtime configuration system:\nVariable Name (without prefix) Description CASDOOR_SERVER_URL URL of the Casdoor authentication server CASDOOR_CLIENT_ID Client ID for Casdoor authentication CASDOOR_CLIENT_SECRET Client secret for Casdoor authentication CASDOOR_APP_NAME Application name in Casdoor CASDOOR_ORG_NAME Organization name in Casdoor CASDOOR_REDIRECT_URI Redirect URI for authentication callbacks CONTACT_FORM_ACTION Action URL for the contact form "},{"id":7,"href":"/docs/docs/deployment/backend-environment/","title":"Backend Environment Variables","section":"Deployment Guides","content":" Backend and Worker Environment Variables # NewsFeed\u0026rsquo;s backend services (API and worker) are configured using environment variables. This page documents all available environment variables and their purpose.\nConfiguration Categories # The backend environment variables are organized into several categories:\nCore Configuration: Basic settings for the backend services Database Configuration: PostgreSQL connection settings Redis Configuration: Redis connection settings FreshRSS Configuration: Settings for the FreshRSS integration Worker Configuration: Settings for the Celery worker and tasks Authentication Configuration: Casdoor authentication settings Core Configuration # Variable Description Default Value BACKEND_DEBUG Enable debug mode for the backend \u0026quot;false\u0026quot; TIMEZONE Timezone for date/time operations \u0026quot;UTC\u0026quot; THUMBNAIL_DIR Directory to store article thumbnails \u0026quot;/thumbnails\u0026quot; Database Configuration # Variable Description Default Value POSTGRES_USER PostgreSQL username \u0026quot;postgres\u0026quot; POSTGRES_PASSWORD PostgreSQL password \u0026quot;postgres\u0026quot; POSTGRES_DB PostgreSQL database name \u0026quot;newsfeed\u0026quot; POSTGRES_HOST PostgreSQL host address \u0026quot;db\u0026quot; POSTGRES_PORT PostgreSQL port \u0026quot;5432\u0026quot; Redis Configuration # Variable Description Default Value REDIS_URL Redis connection URL \u0026quot;redis://redis:6379/0\u0026quot; FreshRSS Configuration # FreshRSS GReader API # Variable Description Default Value FRESHRSS_GREADER_API_URL FreshRSS GReader API URL None FRESHRSS_GREADER_API_USER FreshRSS GReader API username None FRESHRSS_GREADER_API_PASSWORD FreshRSS GReader API password None FreshRSS Python API # Variable Description Default Value FRESHRSS_PYTHON_API_HOST FreshRSS Python API host None FRESHRSS_PYTHON_API_USERNAME FreshRSS Python API username None FRESHRSS_PYTHON_API_PASSWORD FreshRSS Python API password None FRESHRSS_PYTHON_API_VERIFY_SSL Verify SSL certificates \u0026quot;true\u0026quot; FreshRSS Proxy API # Variable Description Default Value FRESHRSS_PROXY_API_URL FreshRSS Proxy API URL None FRESHRSS_PROXY_API_KEY FreshRSS Proxy API key None Worker Configuration # Task Scheduling # Variable Description Default Value WORKER_PROCESS_ARTICLES_INTERVAL How often to process articles (minutes) 15 WORKER_PURGE_OLD_ARTICLES_INTERVAL How often to purge old articles (minutes) 1440 (24 hours) WORKER_ENRICH_ARTICLES_INTERVAL How often to enrich articles (minutes) 60 (1 hour) Article Fetching and Retention # Variable Description Default Value WORKER_FRESHRSS_FETCH_LIMIT Maximum articles to fetch per batch 100 WORKER_CONCURRENT_FRESHRSS_FETCH_TASKS Number of concurrent fetch tasks 1 WORKER_FRESHRSS_FETCH_DAYS Number of days to fetch articles from 3 WORKER_FRESHRSS_PURGE_NUM_DAYS_TO_KEEP Number of days to keep articles 7 Worker Performance # Variable Description Default Value WORKER_TASK_TIME_LIMIT Maximum task runtime (seconds) 300 (5 minutes) WORKER_SOFT_TIME_LIMIT Soft time limit for tasks (seconds) 240 (4 minutes) WORKER_MAX_TASKS_PER_CHILD Tasks per worker before replacement 100 WORKER_MAX_MEMORY_PER_CHILD Memory limit per worker (KB) 200000 (200MB) WORKER_PREFETCH_MULTIPLIER Tasks to prefetch per worker 1 AI Configuration # Variable Description Default Value OLLAMA_URL URL of the Ollama server \u0026quot;http://ollama:11434\u0026quot; OLLAMA_MODEL AI model to use for categorization \u0026quot;LLAMA3.2:3B\u0026quot; Authentication Configuration # Variable Description Default Value CASDOOR_ENDPOINT Casdoor server URL \u0026quot;http://casdoor:8000\u0026quot; CASDOOR_CLIENT_ID Casdoor client ID None CASDOOR_CLIENT_SECRET Casdoor client secret None CASDOOR_ORG Casdoor organization name \u0026quot;newsfeed\u0026quot; CASDOOR_APP_NAME Casdoor application name \u0026quot;newsfeed\u0026quot; CASDOOR_CERT_PUBLIC_KEY Casdoor public key for JWT verification None Example Configuration # Here\u0026rsquo;s an example of a complete backend environment configuration file:\n# Backend and worker configuration REDIS_URL=redis://redis:6379/0 BACKEND_DEBUG=\u0026#34;false\u0026#34; TIMEZONE=America/New_York # Worker Fetch Configuration WORKER_FRESHRSS_FETCH_LIMIT=100 WORKER_CONCURRENT_FRESHRSS_FETCH_TASKS=1 WORKER_FRESHRSS_FETCH_DAYS=3 WORKER_FRESHRSS_PURGE_NUM_DAYS_TO_KEEP=7 # Worker Task Scheduling WORKER_PROCESS_ARTICLES_INTERVAL=15 WORKER_PURGE_OLD_ARTICLES_INTERVAL=1440 WORKER_ENRICH_ARTICLES_INTERVAL=60 # Worker Performance Settings WORKER_TASK_TIME_LIMIT=300 WORKER_SOFT_TIME_LIMIT=240 WORKER_MAX_TASKS_PER_CHILD=100 WORKER_MAX_MEMORY_PER_CHILD=200000 WORKER_PREFETCH_MULTIPLIER=1 # FreshRSS and FreshRSS API Proxy Setup FRESHRSS_GREADER_API_URL=https://freshrss.example.com/api/greader.php FRESHRSS_GREADER_API_USER=newsfeed FRESHRSS_GREADER_API_PASSWORD=your_password_here FRESHRSS_PYTHON_API_HOST=https://freshrss.example.com FRESHRSS_PYTHON_API_USERNAME=newsfeed FRESHRSS_PYTHON_API_PASSWORD=your_password_here FRESHRSS_PYTHON_API_VERIFY_SSL=true # Ollama Configuration OLLAMA_URL=http://ollama:11434 OLLAMA_MODEL=LLAMA3.2:3B # Database configuration POSTGRES_USER=postgres POSTGRES_PASSWORD=secure_password_here POSTGRES_DB=newsfeed POSTGRES_HOST=db # Casdoor Configuration CASDOOR_ENDPOINT=http://casdoor:8000 CASDOOR_CLIENT_ID=your_client_id_here CASDOOR_CLIENT_SECRET=your_client_secret_here CASDOOR_ORG=newsfeed CASDOOR_APP_NAME=newsfeed CASDOOR_CERT_PUBLIC_KEY=\u0026#34;-----BEGIN PUBLIC KEY----- ... -----END PUBLIC KEY-----\u0026#34; Environment Variable Precedence # Environment variables can be set in multiple ways, with the following precedence (highest to lowest):\nDocker Compose environment variables Environment file (env/backend) Default values in the code Sensitive Information # For production deployments, sensitive information such as passwords and API keys should be managed securely:\nUse environment variables instead of hardcoding values Consider using Docker secrets or a secure vault service Rotate credentials regularly Use different credentials for development and production environments Debugging # When troubleshooting issues with the backend or worker services, the following environment variables can be helpful:\nSet BACKEND_DEBUG=\u0026quot;true\u0026quot; to enable detailed logging Adjust worker task limits (WORKER_TASK_TIME_LIMIT, WORKER_SOFT_TIME_LIMIT) if tasks are timing out Modify WORKER_FRESHRSS_FETCH_LIMIT if you\u0026rsquo;re experiencing performance issues during article fetching "},{"id":8,"href":"/docs/docs/deployment/nginx-configuration/","title":"Nginx Configuration","section":"Deployment Guides","content":" Nginx Configuration # NewsFeed uses Nginx as a reverse proxy to route requests to the appropriate services and to serve static content. This page documents the Nginx configuration and optimizations.\nMulti-Stage Docker Build # The Nginx service uses a multi-stage Docker build to optimize the image size and build process:\nDocumentation Build Stage: Builds the Hugo documentation Nginx Base Stage: Sets up the base Nginx configuration Production Stage: Creates the final optimized image # ---- Hugo Documentation Build Stage ---- FROM ghcr.io/gohugoio/hugo:v0.147.8 AS docs-builder # ... builds the documentation # ---- Nginx Base Stage ---- FROM nginx:stable-alpine AS nginx-base # ... installs dependencies # ---- Production Stage ---- FROM nginx-base AS production # ... creates the final image Nginx Configuration # The Nginx configuration is structured to efficiently route requests and serve static content:\nWorker Configuration # user nginx; worker_processes auto; worker_rlimit_nofile 65535; events { worker_connections 4096; } worker_processes auto: Automatically sets the number of worker processes based on CPU cores worker_rlimit_nofile 65535: Increases the file descriptor limit worker_connections 4096: Increases the maximum number of simultaneous connections HTTP Configuration # http { include /etc/nginx/mime.types; default_type application/octet-stream; # Security headers add_header X-Content-Type-Options \u0026#34;nosniff\u0026#34; always; add_header X-Frame-Options \u0026#34;SAMEORIGIN\u0026#34; always; add_header X-XSS-Protection \u0026#34;1; mode=block\u0026#34; always; add_header Referrer-Policy \u0026#34;strict-origin-when-cross-origin\u0026#34; always; # Performance optimizations sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; client_max_body_size 10M; gzip on; gzip_comp_level 6; gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript; } Upstream Configuration # # Upstream for backend upstream backend { server backend:8001; } # Upstream for frontend app upstream frontend { server frontend:3000; } Server Configuration # server { listen 80; server_name _; # Support for proxy headers real_ip_header X-Forwarded-For; set_real_ip_from 0.0.0.0/0; # Serve documentation location /docs/ { alias /docs/public/; try_files $uri $uri/ /docs/index.html; add_header Cache-Control \u0026#34;public, max-age=3600\u0026#34;; } # Serve thumbnails as static files location /thumbnails/ { alias /thumbnails/; add_header Cache-Control \u0026#34;public, max-age=86400\u0026#34;; try_files $uri =404; } # Proxy /api to backend location /api/ { proxy_pass http://backend/api/; # ... proxy headers } # Proxy everything else to frontend location / { proxy_pass http://frontend/; # ... proxy headers } } Performance Optimizations # The Nginx configuration includes several performance optimizations:\nGzip Compression # gzip on; gzip_comp_level 6; gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript; This reduces the size of transmitted data, improving load times.\nStatic File Caching # location /docs/ { add_header Cache-Control \u0026#34;public, max-age=3600\u0026#34;; } location /thumbnails/ { add_header Cache-Control \u0026#34;public, max-age=86400\u0026#34;; } Caching static files reduces server load and improves client performance.\nTCP Optimizations # sendfile on; tcp_nopush on; tcp_nodelay on; These settings optimize TCP packet handling for better performance.\nConnection Handling # keepalive_timeout 65; Keeps connections open for 65 seconds, reducing the overhead of establishing new connections.\nSecurity Enhancements # Non-Root User # The Nginx service runs as a non-root user for improved security:\n# Create non-root user for nginx RUN addgroup -g 101 -S nginx \u0026amp;\u0026amp; \\ adduser -S -D -H -u 101 -h /var/cache/nginx -s /sbin/nologin -G nginx -g nginx nginx # Use non-root user USER nginx Security Headers # add_header X-Content-Type-Options \u0026#34;nosniff\u0026#34; always; add_header X-Frame-Options \u0026#34;SAMEORIGIN\u0026#34; always; add_header X-XSS-Protection \u0026#34;1; mode=block\u0026#34; always; add_header Referrer-Policy \u0026#34;strict-origin-when-cross-origin\u0026#34; always; These headers protect against common web vulnerabilities.\nHealth Checks # The Nginx service includes a health check to ensure it\u0026rsquo;s functioning correctly:\nHEALTHCHECK --interval=30s --timeout=5s --start-period=5s --retries=3 \\ CMD curl -f http://localhost/docs/ || exit 1 This checks if the documentation is being served correctly every 30 seconds.\nDocker Compose Integration # The docker-compose.yml file is configured to build and run the Nginx service:\nnginx: image: beardedtek/newsfeed-nginx:latest build: context: . dockerfile: nginx/Dockerfile target: production ports: - \u0026#34;8880:80\u0026#34; volumes: - thumbnails:/thumbnails:ro healthcheck: test: [\u0026#34;CMD\u0026#34;, \u0026#34;curl\u0026#34;, \u0026#34;-f\u0026#34;, \u0026#34;http://localhost/docs/\u0026#34;] interval: 30s timeout: 5s retries: 3 start_period: 10s Customizing the Configuration # To customize the Nginx configuration:\nEdit the nginx/proxy.conf file Rebuild the Nginx image: docker-compose build nginx Restart the service: docker-compose restart nginx Best Practices # Regularly update the Nginx base image for security patches Monitor Nginx logs for errors or performance issues Adjust worker connections and processes based on server resources Consider adding rate limiting for production deployments "},{"id":9,"href":"/docs/docs/deployment/ci-cd/","title":"Continuous Integration and Deployment","section":"Deployment Guides","content":" Continuous Integration and Deployment # NewsFeed uses GitHub Actions for continuous integration and deployment (CI/CD). This page documents the CI/CD process and how to use it.\nDocker Image Publishing # The main CI/CD workflow builds and publishes Docker images for the NewsFeed application. These images are published to Docker Hub and can be used for deployment.\nImages Published # The workflow builds and publishes the following Docker images:\nbeardedtek/newsfeed-nginx - The Nginx service with documentation beardedtek/newsfeed - The frontend service beardedtek/newsfeed-backend - The backend service Tags # Each image is tagged with:\n:latest - For the default branch (main) :\u0026lt;branch\u0026gt; - The branch name (e.g., main, develop) :\u0026lt;commit\u0026gt; - The short SHA of the commit This allows you to use specific versions of the images in your deployment, or always use the latest version.\nWorkflow Triggers # The CI/CD workflow is triggered on:\nPush to main or develop branches Pull requests to main or develop branches Push of version tags (e.g., v1.0.0) Images are only pushed to Docker Hub on push events, not on pull requests. This ensures that only approved changes are published.\nUsing the Published Images # To use the published images in your deployment, you can reference them in your docker-compose.yml file:\nservices: nginx: image: beardedtek/newsfeed-nginx:latest # ... frontend: image: beardedtek/newsfeed:latest # ... backend: image: beardedtek/newsfeed-backend:latest # ... For production deployments, it\u0026rsquo;s recommended to use a specific version tag instead of latest:\nservices: nginx: image: beardedtek/newsfeed-nginx:v1.0.0 # ... Setting Up CI/CD for Your Fork # If you fork the NewsFeed repository, you\u0026rsquo;ll need to set up the following secrets in your GitHub repository to enable the CI/CD workflow:\nDOCKERHUB_USERNAME - Your Docker Hub username DOCKERHUB_TOKEN - A Docker Hub access token (not your password) Creating a Docker Hub Access Token # Log in to Docker Hub Go to Account Settings \u0026gt; Security Click \u0026ldquo;New Access Token\u0026rdquo; Give it a name (e.g., \u0026ldquo;GitHub Actions\u0026rdquo;) Copy the token and add it as a secret in your GitHub repository Adding Secrets to GitHub # Go to your GitHub repository Click on \u0026ldquo;Settings\u0026rdquo; \u0026gt; \u0026ldquo;Secrets and variables\u0026rdquo; \u0026gt; \u0026ldquo;Actions\u0026rdquo; Click \u0026ldquo;New repository secret\u0026rdquo; Add the following secrets: Name: DOCKERHUB_USERNAME, Value: Your Docker Hub username Name: DOCKERHUB_TOKEN, Value: Your Docker Hub access token Customizing the CI/CD Workflow # The CI/CD workflow is defined in the .github/workflows/docker-publish.yml file. You can customize it to suit your needs, such as:\nAdding more branches to the trigger list Changing the tag format Adding more Docker images Adding build arguments Configuring additional platforms (e.g., for multi-architecture builds) Automated Deployments # Currently, the CI/CD workflow only builds and publishes Docker images. It does not automatically deploy them to any environment. You can extend the workflow to deploy to your environment by adding additional steps to the workflow.\nFor example, to deploy to a server using SSH:\n- name: Deploy to production if: github.ref == \u0026#39;refs/heads/main\u0026#39; uses: appleboy/ssh-action@master with: host: ${{ secrets.SSH_HOST }} username: ${{ secrets.SSH_USERNAME }} key: ${{ secrets.SSH_PRIVATE_KEY }} script: | cd /path/to/newsfeed docker-compose pull docker-compose up -d This would require additional secrets:\nSSH_HOST - The hostname or IP address of your server SSH_USERNAME - The username to use for SSH SSH_PRIVATE_KEY - The private key to use for SSH authentication "},{"id":10,"href":"/docs/docs/authentication/","title":"Authentication","section":"Documentation","content":" Authentication # This section provides detailed information about the authentication system in NewsFeed.\nOverview # NewsFeed uses Casdoor for authentication and user management. Casdoor is an open-source Identity and Access Management (IAM) solution that provides:\nUser authentication Single Sign-On (SSO) OAuth 2.0 support User management Role-based access control Authentication Flow # The authentication flow in NewsFeed works as follows:\nUser clicks \u0026ldquo;Login\u0026rdquo; in the NewsFeed interface User is redirected to the Casdoor login page After successful authentication, Casdoor redirects back to NewsFeed with an authorization code NewsFeed exchanges the code for an access token The access token is stored in the browser and used for subsequent API requests Backend Authentication # The backend authenticates API requests using:\nJWT token validation Public key verification Role-based access control JWT Verification # The backend verifies JWT tokens by:\nExtracting the token from the Authorization header Verifying the token signature using Casdoor\u0026rsquo;s public key Validating token claims (expiration, issuer, etc.) Extracting user information from the token Configuration # Casdoor Configuration # Casdoor is configured through environment variables:\n# Casdoor Configuration CASDOOR_ENDPOINT=http://casdoor:8000 CASDOOR_CLIENT_ID=your-client-id CASDOOR_CLIENT_SECRET=your-client-secret CASDOOR_ORG=newsfeed CASDOOR_APP_NAME=newsfeed CASDOOR_CERT_PUBLIC_KEY=\u0026#34;-----BEGIN PUBLIC KEY----- ... -----END PUBLIC KEY-----\u0026#34; Frontend Configuration # The frontend is configured through environment variables:\n# Casdoor configuration NEXT_PUBLIC_CASDOOR_SERVER_URL=http://localhost:8000 NEXT_PUBLIC_CASDOOR_CLIENT_ID=your-client-id NEXT_PUBLIC_CASDOOR_CLIENT_SECRET=your-client-secret NEXT_PUBLIC_CASDOOR_APP_NAME=newsfeed NEXT_PUBLIC_CASDOOR_ORG_NAME=newsfeed NEXT_PUBLIC_CASDOOR_REDIRECT_URI=http://localhost:8880/callback User Roles # NewsFeed supports the following user roles:\nAnonymous - Unauthenticated users with limited access User - Standard authenticated users Admin - Users with administrative privileges Role-Based Access # Different API endpoints have different access requirements:\nPublic endpoints (no authentication required) User endpoints (authentication required) Admin endpoints (admin role required) Custom Authentication # If you need to use a different authentication system:\nModify the auth.py file in the backend Update the AuthContext.tsx file in the frontend Configure your authentication provider Update the authentication flow Troubleshooting # Common authentication issues:\nInvalid Token # Symptoms: API requests fail with 401 Unauthorized\nSolutions:\nCheck that the token is being sent correctly Verify token expiration Ensure the public key is configured correctly CORS Issues # Symptoms: Authentication fails due to CORS errors\nSolutions:\nConfigure CORS settings in the backend Ensure the redirect URI is configured correctly Check browser console for specific CORS errors Casdoor Connection Issues # Symptoms: Unable to connect to Casdoor\nSolutions:\nVerify Casdoor is running Check network connectivity between services Validate Casdoor configuration "},{"id":11,"href":"/docs/docs/deployment/git-hooks/","title":"Git Hooks","section":"Deployment Guides","content":" Git Hooks # NewsFeed includes Git hooks to automate certain tasks during development and deployment.\nAvailable Hooks # Pre-commit Hook # The pre-commit hook automatically rebuilds the documentation site when files in the docs/ or content/ directories are modified. This ensures that the documentation is always up-to-date with the latest changes.\nWhat it does # When you commit changes that include modifications to files in the docs/ or content/ directories, the pre-commit hook:\nTemporarily stashes any unstaged changes Runs the docs/build.sh script to rebuild the documentation Adds the generated files to your commit Restores any stashed changes Allows the commit to proceed if the build was successful Benefits # Ensures documentation is always built before committing Prevents outdated or broken documentation from being committed Automates the documentation build process Maintains consistency across the project Installation # To install the Git hooks:\n./scripts/install-hooks.sh This script will:\nCreate the .git/hooks directory if it doesn\u0026rsquo;t exist Copy the pre-commit hook to the appropriate location Make the hook executable Manual Setup # If you prefer to set up the hooks manually:\n# Create hooks directory if it doesn\u0026#39;t exist mkdir -p .git/hooks # Copy the pre-commit hook cp scripts/hooks/pre-commit .git/hooks/ # Make it executable chmod +x .git/hooks/pre-commit Skipping Hooks # If you need to bypass the pre-commit hook for a specific commit:\ngit commit --no-verify -m \u0026#34;Your commit message\u0026#34; However, this is not recommended as it may lead to inconsistent documentation.\nTroubleshooting # Hook Not Running # If the pre-commit hook is not running:\nEnsure the hook is executable:\nchmod +x .git/hooks/pre-commit Verify the hook is in the correct location:\nls -la .git/hooks/pre-commit Documentation Build Failing # If the documentation build fails during the pre-commit hook:\nRun the build script manually to see the error:\ncd docs ./build.sh Fix any issues in the documentation\nTry committing again\n"},{"id":12,"href":"/docs/docs/deployment/","title":"Deployment Guides","section":"Documentation","content":" Deployment Guides # This section provides detailed information on deploying NewsFeed in various environments.\nDocker Deployment # NewsFeed is designed to be deployed using Docker and Docker Compose. The project includes a production-ready docker-compose.yml file with optimized container configurations. For detailed information about our Docker optimizations, see the Docker Optimizations page.\nPrerequisites # Docker Engine (20.10+) Docker Compose (2.0+) At least 2GB of RAM At least 10GB of disk space Basic Deployment Steps # Clone the repository:\ngit clone https://github.com/beardedtek/newsfeed.git cd newsfeed Set up environment variables:\n# Create environment files from examples cp env/frontend.example env/frontend cp env/backend.example env/backend # Edit the environment files with your configuration nano env/frontend nano env/backend Create Docker networks:\ndocker network create newsfeed docker network create casdoor Start the services:\ndocker-compose up -d Monitor the logs:\ndocker-compose logs -f Production Considerations # For production deployments, consider the following:\nSecurity:\nUse strong passwords for all services Configure SSL/TLS for all external access Restrict access to admin endpoints Performance:\nAdjust worker concurrency based on available resources Configure appropriate cache settings Consider using a CDN for static assets Reliability:\nSet up monitoring and alerting Configure regular backups Implement health checks Continuous Integration and Deployment # NewsFeed includes a GitHub Actions workflow for continuous integration and deployment. This workflow automatically builds and publishes Docker images for the NewsFeed application. For detailed information, see the Continuous Integration and Deployment page.\nPre-built Images # You can use the pre-built Docker images from Docker Hub in your deployment:\nservices: nginx: image: beardedtek/newsfeed-nginx:latest # ... frontend: image: beardedtek/newsfeed:latest # ... backend: image: beardedtek/newsfeed-backend:latest # ... Nginx Configuration # NewsFeed uses a custom Nginx container (beardedtek/newsfeed-nginx:latest) that is optimized for production use. This container:\nServes the documentation site at /docs/ Acts as a reverse proxy for the frontend and backend services Includes performance optimizations for better response times Automatically builds the documentation during image creation For detailed information about the Nginx configuration, see the Nginx Configuration page.\nBuilding the Nginx Image # The Nginx image uses a multi-stage build process to optimize size and performance:\n# Build just the nginx image docker build -t beardedtek/newsfeed-nginx:latest -f nginx/Dockerfile . # Or build all services including nginx docker-compose build Key Features # Multi-stage build: Documentation is built in a separate stage Performance optimizations: Increased worker connections, file descriptors, and TCP optimizations Security enhancements: Runs as non-root user, includes security headers Health checks: Automatic monitoring of service health Reverse Proxy Configuration # NewsFeed is designed to be deployed behind a reverse proxy. The following sections provide configuration examples for popular reverse proxies.\nNginx # server { listen 80; server_name newsfeed.example.com; # Redirect HTTP to HTTPS return 301 https://$host$request_uri; } server { listen 443 ssl http2; server_name newsfeed.example.com; # SSL configuration ssl_certificate /path/to/fullchain.pem; ssl_certificate_key /path/to/privkey.pem; ssl_protocols TLSv1.2 TLSv1.3; # Proxy to NewsFeed location / { proxy_pass http://localhost:80; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; } # Documentation location /docs/ { proxy_pass http://localhost:80/docs/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; } } Traefik # # docker-compose.override.yml services: nginx: labels: - \u0026#34;traefik.enable=true\u0026#34; - \u0026#34;traefik.http.routers.newsfeed.rule=Host(`newsfeed.example.com`)\u0026#34; - \u0026#34;traefik.http.routers.newsfeed.entrypoints=websecure\u0026#34; - \u0026#34;traefik.http.routers.newsfeed.tls.certresolver=myresolver\u0026#34; - \u0026#34;traefik.http.services.newsfeed.loadbalancer.server.port=80\u0026#34; Caddy # newsfeed.example.com { reverse_proxy /* localhost:80 } Scaling # For larger deployments, consider:\nHorizontal Scaling:\nAdd more worker containers Use a load balancer for frontend/backend services Database Scaling:\nConfigure PostgreSQL replication Consider using a managed database service Cache Optimization:\nIncrease Redis memory allocation Implement distributed caching Backup and Recovery # To back up your NewsFeed instance:\nDatabase Backup:\ndocker-compose exec db pg_dump -U postgres -d newsfeed \u0026gt; backup.sql Volume Backup:\n# Backup thumbnails tar -czvf thumbnails-backup.tar.gz /path/to/thumbnails/volume Configuration Backup:\n# Backup environment files cp -r env/ env-backup/ To restore from backup:\nDatabase Restore:\ncat backup.sql | docker-compose exec -T db psql -U postgres -d newsfeed Volume Restore:\n# Restore thumbnails tar -xzvf thumbnails-backup.tar.gz -C /path/to/restore/location Upgrading # To upgrade your NewsFeed instance:\nPull the latest changes:\ngit pull Rebuild and restart the services:\ndocker-compose down docker-compose build docker-compose up -d Run any necessary migrations:\ndocker-compose exec backend python -m app.init_db "},{"id":13,"href":"/docs/docs/platforms/","title":"Platform-Specific Guides","section":"Documentation","content":" Platform-Specific Guides # This section provides detailed information on deploying NewsFeed on specific platforms.\nWindows # Prerequisites # Windows 10/11 with WSL2 enabled Docker Desktop for Windows Git for Windows Installation Steps # Install WSL2:\nOpen PowerShell as Administrator Run: wsl --install Restart your computer Install Docker Desktop:\nDownload from Docker Desktop During installation, ensure WSL2 integration is enabled Clone the Repository:\n# Using PowerShell git clone https://github.com/beardedtek/newsfeed.git cd newsfeed Configure Environment:\nCopy example environment files:\ncopy env\\frontend.example env\\frontend copy env\\backend.example env\\backend Edit the files with your preferred text editor\nCreate Docker Networks:\ndocker network create newsfeed docker network create casdoor Start the Services:\ndocker-compose up -d Access NewsFeed:\nOpen a browser and navigate to http://localhost:80 Windows-Specific Considerations # File Permissions: WSL2 and Windows handle file permissions differently. If you encounter permission issues, check the file ownership and permissions in WSL. Performance: For better performance, store the project files in the WSL2 filesystem rather than the Windows filesystem. Resource Allocation: Adjust Docker Desktop resource allocation (memory, CPU) in the settings if needed. Proxmox # Prerequisites # Proxmox VE 7.0+ LXC container or VM with Docker support At least 2GB RAM and 2 CPU cores Installation Steps # Create an LXC Container or VM:\nFor LXC: Use a Ubuntu 22.04 template with nesting enabled For VM: Install Ubuntu 22.04 Server Install Docker and Docker Compose:\n# Update system apt update \u0026amp;\u0026amp; apt upgrade -y # Install dependencies apt install -y apt-transport-https ca-certificates curl software-properties-common # Add Docker repository curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add - add-apt-repository \u0026#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\u0026#34; # Install Docker apt update apt install -y docker-ce docker-compose Clone the Repository:\ngit clone https://github.com/beardedtek/newsfeed.git cd newsfeed Configure Environment:\ncp env/frontend.example env/frontend cp env/backend.example env/backend # Edit the files nano env/frontend nano env/backend Create Docker Networks:\ndocker network create newsfeed docker network create casdoor Start the Services:\ndocker-compose up -d Proxmox-Specific Considerations # Resource Allocation: Adjust CPU and memory resources in Proxmox as needed. Storage: Consider using a dedicated storage volume for the database and thumbnails. Networking: Configure appropriate network settings in Proxmox for external access. Unraid # Prerequisites # Unraid 6.9+ Docker support enabled Community Applications (CA) installed Installation Steps # Install Docker:\nEnsure Docker is enabled in Unraid settings Create App Folder:\nCreate a folder for NewsFeed in your appdata share:\nmkdir -p /mnt/user/appdata/newsfeed Clone the Repository:\ncd /mnt/user/appdata/newsfeed git clone https://github.com/beardedtek/newsfeed.git . Configure Environment:\ncp env/frontend.example env/frontend cp env/backend.example env/backend # Edit the files nano env/frontend nano env/backend Create Docker Networks:\ndocker network create newsfeed docker network create casdoor Start the Services:\ndocker-compose up -d Add to Unraid Startup:\nCreate a user script in Unraid to start NewsFeed on system boot Unraid-Specific Considerations # Persistence: Store data on the array, not on the cache drive, for better data protection. Backup: Use Unraid\u0026rsquo;s built-in backup solutions for the NewsFeed data. Monitoring: Use Unraid\u0026rsquo;s Docker monitoring features to keep track of container health. QNAP # Prerequisites # QNAP NAS with Container Station installed At least 2GB of RAM available for containers Installation Steps # Install Container Station:\nOpen the App Center Find and install Container Station Enable SSH:\nOpen Control Panel \u0026gt; Network \u0026amp; File Services \u0026gt; Telnet/SSH Enable SSH and set a port SSH into QNAP:\nssh admin@qnap-ip-address Install Docker Compose:\ncurl -L \u0026#34;https://github.com/docker/compose/releases/download/v2.18.1/docker-compose-$(uname -s)-$(uname -m)\u0026#34; -o /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose Create Project Directory:\nmkdir -p /share/Container/newsfeed cd /share/Container/newsfeed Clone the Repository:\ngit clone https://github.com/beardedtek/newsfeed.git . Configure Environment:\ncp env/frontend.example env/frontend cp env/backend.example env/backend # Edit the files nano env/frontend nano env/backend Create Docker Networks:\ndocker network create newsfeed docker network create casdoor Start the Services:\ndocker-compose up -d QNAP-Specific Considerations # Resource Limitations: QNAP NAS devices may have limited resources. Monitor container performance. Persistence: Store data on a volume that is included in your backup routine. Network Configuration: Configure port forwarding in QNAP\u0026rsquo;s network settings if you want to access NewsFeed from outside your network. "}]